{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how many of the generated headlines are compliant with:\n",
    "\n",
    "- the original headline\n",
    "- the original article\n",
    "\n",
    "using the provided classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-28 19:02:00--  https://unipiit-my.sharepoint.com/:u:/g/personal/l_demattei_studenti_unipi_it/Ee6SwfKkLzFJk-_1ho3LXFUB0fZlADKGdod42qM0dmvGZA?download=1\n",
      "Resolving unipiit-my.sharepoint.com (unipiit-my.sharepoint.com)... 13.107.136.9\n",
      "Connecting to unipiit-my.sharepoint.com (unipiit-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /personal/l_demattei_studenti_unipi_it/Documents/h-a-bm-classifiers.h5?&originalPath=aHR0cHM6Ly91bmlwaWl0LW15LnNoYXJlcG9pbnQuY29tLzp1Oi9nL3BlcnNvbmFsL2xfZGVtYXR0ZWlfc3R1ZGVudGlfdW5pcGlfaXQvRWU2U3dmS2tMekZKay1fMWhvM0xYRlVCMGZabEFES0dkb2Q0MnFNMGRtdkdaQT9ydGltZT16SFc1LTRSTDJFZw [following]\n",
      "--2020-08-28 19:02:01--  https://unipiit-my.sharepoint.com/personal/l_demattei_studenti_unipi_it/Documents/h-a-bm-classifiers.h5?&originalPath=aHR0cHM6Ly91bmlwaWl0LW15LnNoYXJlcG9pbnQuY29tLzp1Oi9nL3BlcnNvbmFsL2xfZGVtYXR0ZWlfc3R1ZGVudGlfdW5pcGlfaXQvRWU2U3dmS2tMekZKay1fMWhvM0xYRlVCMGZabEFES0dkb2Q0MnFNMGRtdkdaQT9ydGltZT16SFc1LTRSTDJFZw\n",
      "Reusing existing connection to unipiit-my.sharepoint.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 711464552 (679M) [application/octet-stream]\n",
      "Saving to: ‘h-a-classifier.h5’\n",
      "\n",
      "h-a-classifier.h5   100%[===================>] 678.50M  1.54MB/s    in 6m 52s  \n",
      "\n",
      "2020-08-28 19:08:53 (1.65 MB/s) - ‘h-a-classifier.h5’ saved [711464552/711464552]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O h-a-classifier.h5 https://unipiit-my.sharepoint.com/:u:/g/personal/l_demattei_studenti_unipi_it/Ee6SwfKkLzFJk-_1ho3LXFUB0fZlADKGdod42qM0dmvGZA?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-28 19:08:53--  https://unipiit-my.sharepoint.com/:u:/g/personal/l_demattei_studenti_unipi_it/EZhDwNJSfz1No5WT9t5hOjMB7zrXdJBBu2dGEZCxElIhqA?download=1\n",
      "Resolving unipiit-my.sharepoint.com (unipiit-my.sharepoint.com)... 13.107.136.9\n",
      "Connecting to unipiit-my.sharepoint.com (unipiit-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /personal/l_demattei_studenti_unipi_it/Documents/h-h-bm-classifiers.h5?&originalPath=aHR0cHM6Ly91bmlwaWl0LW15LnNoYXJlcG9pbnQuY29tLzp1Oi9nL3BlcnNvbmFsL2xfZGVtYXR0ZWlfc3R1ZGVudGlfdW5pcGlfaXQvRVpoRHdOSlNmejFObzVXVDl0NWhPak1CN3pyWGRKQkJ1MmRHRVpDeEVsSWhxQT9ydGltZT10MkhzOFlWTDJFZw [following]\n",
      "--2020-08-28 19:08:54--  https://unipiit-my.sharepoint.com/personal/l_demattei_studenti_unipi_it/Documents/h-h-bm-classifiers.h5?&originalPath=aHR0cHM6Ly91bmlwaWl0LW15LnNoYXJlcG9pbnQuY29tLzp1Oi9nL3BlcnNvbmFsL2xfZGVtYXR0ZWlfc3R1ZGVudGlfdW5pcGlfaXQvRVpoRHdOSlNmejFObzVXVDl0NWhPak1CN3pyWGRKQkJ1MmRHRVpDeEVsSWhxQT9ydGltZT10MkhzOFlWTDJFZw\n",
      "Reusing existing connection to unipiit-my.sharepoint.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 711464244 (679M) [application/octet-stream]\n",
      "Saving to: ‘h-h-classifier.h5’\n",
      "\n",
      "h-h-classifier.h5    61%[===========>        ] 420.34M  1.50MB/s    in 4m 15s  \n",
      "\n",
      "2020-08-28 19:13:09 (1.65 MB/s) - Read error at byte 440754934/711464244 (Connection reset by peer). Retrying.\n",
      "\n",
      "--2020-08-28 19:13:10--  (try: 2)  https://unipiit-my.sharepoint.com/personal/l_demattei_studenti_unipi_it/Documents/h-h-bm-classifiers.h5?&originalPath=aHR0cHM6Ly91bmlwaWl0LW15LnNoYXJlcG9pbnQuY29tLzp1Oi9nL3BlcnNvbmFsL2xfZGVtYXR0ZWlfc3R1ZGVudGlfdW5pcGlfaXQvRVpoRHdOSlNmejFObzVXVDl0NWhPak1CN3pyWGRKQkJ1MmRHRVpDeEVsSWhxQT9ydGltZT10MkhzOFlWTDJFZw\n",
      "Connecting to unipiit-my.sharepoint.com (unipiit-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 PARTIAL CONTENT\n",
      "Length: 711464244 (679M), 270709310 (258M) remaining [application/octet-stream]\n",
      "Saving to: ‘h-h-classifier.h5’\n",
      "\n",
      "h-h-classifier.h5   100%[++++++++++++=======>] 678.50M  1.69MB/s    in 2m 36s  \n",
      "\n",
      "2020-08-28 19:15:46 (1.66 MB/s) - ‘h-h-classifier.h5’ saved [711464244/711464244]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O h-h-classifier.h5 https://unipiit-my.sharepoint.com/:u:/g/personal/l_demattei_studenti_unipi_it/EZhDwNJSfz1No5WT9t5hOjMB7zrXdJBBu2dGEZCxElIhqA?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['rep_original_headlines', 'rep_original_fulltext', 'gio_generated_headlines'])\n",
    "dataset['rep_original_headlines'] = open('../rep/val_rep_h.txt', 'r').read().splitlines()\n",
    "dataset['rep_original_fulltext'] = open('../rep/val_rep_ft.txt', 'r').read().splitlines()\n",
    "dataset['gio_generated_headlines'] = open('../pred.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep_original_headlines</th>\n",
       "      <th>rep_original_fulltext</th>\n",
       "      <th>gio_generated_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decreto sicurezza, denunciati per accattonaggi...</td>\n",
       "      <td>BRESCIA - Per la prima volta nel Bresciano vie...</td>\n",
       "      <td>Bresciano nel Bresciano Gesù: contestato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sicilia, i siriani scampati al naufragio riabb...</td>\n",
       "      <td>SANT'ANGELO MUXARO (Agrigento) - \"Karim\". È un...</td>\n",
       "      <td>Agrigento, strozzata strozzata dall'emozione,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stati Uniti, uragano Florence: polemica sulle ...</td>\n",
       "      <td>WASHINGTON. \"Florence è molto pericoloso però ...</td>\n",
       "      <td>Ecco i politici del Nord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se il pentastellato parla da Le Pen</td>\n",
       "      <td>Populismo è ormai una parola \"malata\", un cont...</td>\n",
       "      <td>Anis Amri a Grillo dopo la morte di Grillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La soluzione dello schema del 2 Dicembre 2017</td>\n",
       "      <td>Torna al cruciverba Torna all'indice della rub...</td>\n",
       "      <td>Il rubrica della fiamma Scrivi della chiesa al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12735</th>\n",
       "      <td>Thailandia, destituita la premier per abuso di...</td>\n",
       "      <td>BANGKOK - Ciò che non era riuscito all'opposiz...</td>\n",
       "      <td>sorella del Nord, progressi la sorella del</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12736</th>\n",
       "      <td>Geronimo Stilton: \"Su carta o in digitale conq...</td>\n",
       "      <td>Il re italiano indiscusso dei bestseller è un ...</td>\n",
       "      <td>Il commento dei bestseller è un topo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12737</th>\n",
       "      <td>\"BlackBerry pensa a lanciare uno smartphone co...</td>\n",
       "      <td>SE CONFERMATA, la notizia avrebbe del clamoros...</td>\n",
       "      <td>BlackBerry sceglie la linea: recensione nel 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12738</th>\n",
       "      <td>Nardella: \"Cuperlo ammetta la sconfitta. La sc...</td>\n",
       "      <td>FIRENZE - \"Il giorno dopo le elezioni hanno vi...</td>\n",
       "      <td>D'Alema e i cuperliani Cuperlo di Renzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12739</th>\n",
       "      <td>Corruzione, Davigo: \"Non tutti rubano, ma la p...</td>\n",
       "      <td>TARANTO - Dopo il \"costruttivo\" incontro con i...</td>\n",
       "      <td>Taranto, relazionando al \"costruttivo\" dalla p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  rep_original_headlines  \\\n",
       "0      Decreto sicurezza, denunciati per accattonaggi...   \n",
       "1      Sicilia, i siriani scampati al naufragio riabb...   \n",
       "2      Stati Uniti, uragano Florence: polemica sulle ...   \n",
       "3                    Se il pentastellato parla da Le Pen   \n",
       "4          La soluzione dello schema del 2 Dicembre 2017   \n",
       "...                                                  ...   \n",
       "12735  Thailandia, destituita la premier per abuso di...   \n",
       "12736  Geronimo Stilton: \"Su carta o in digitale conq...   \n",
       "12737  \"BlackBerry pensa a lanciare uno smartphone co...   \n",
       "12738  Nardella: \"Cuperlo ammetta la sconfitta. La sc...   \n",
       "12739  Corruzione, Davigo: \"Non tutti rubano, ma la p...   \n",
       "\n",
       "                                   rep_original_fulltext  \\\n",
       "0      BRESCIA - Per la prima volta nel Bresciano vie...   \n",
       "1      SANT'ANGELO MUXARO (Agrigento) - \"Karim\". È un...   \n",
       "2      WASHINGTON. \"Florence è molto pericoloso però ...   \n",
       "3      Populismo è ormai una parola \"malata\", un cont...   \n",
       "4      Torna al cruciverba Torna all'indice della rub...   \n",
       "...                                                  ...   \n",
       "12735  BANGKOK - Ciò che non era riuscito all'opposiz...   \n",
       "12736  Il re italiano indiscusso dei bestseller è un ...   \n",
       "12737  SE CONFERMATA, la notizia avrebbe del clamoros...   \n",
       "12738  FIRENZE - \"Il giorno dopo le elezioni hanno vi...   \n",
       "12739  TARANTO - Dopo il \"costruttivo\" incontro con i...   \n",
       "\n",
       "                                 gio_generated_headlines  \n",
       "0               Bresciano nel Bresciano Gesù: contestato  \n",
       "1          Agrigento, strozzata strozzata dall'emozione,  \n",
       "2                               Ecco i politici del Nord  \n",
       "3             Anis Amri a Grillo dopo la morte di Grillo  \n",
       "4      Il rubrica della fiamma Scrivi della chiesa al...  \n",
       "...                                                  ...  \n",
       "12735         sorella del Nord, progressi la sorella del  \n",
       "12736               Il commento dei bestseller è un topo  \n",
       "12737   BlackBerry sceglie la linea: recensione nel 2009  \n",
       "12738            D'Alema e i cuperliani Cuperlo di Renzi  \n",
       "12739  Taranto, relazionando al \"costruttivo\" dalla p...  \n",
       "\n",
       "[12740 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "HH_MAX_LEN = 64\n",
    "HH_VALID_BATCH_SIZE = 128\n",
    "HA_MAX_LEN = 512\n",
    "HA_VALID_BATCH_SIZE = 8\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, field):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.field = field\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.field == 'fulltext':\n",
    "            rep_orginal = str(self.data.rep_original_fulltext[index])\n",
    "        else:\n",
    "            rep_orginal = str(self.data.rep_original_headlines[index])\n",
    "        rep_orginal = \" \".join(rep_orginal.split())\n",
    "        \n",
    "        \n",
    "        gio_headline_generated = str(self.data.gio_generated_headlines[index])\n",
    "        gio_headline_generated = \" \".join(gio_headline_generated.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            rep_orginal,\n",
    "            gio_headline_generated,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        #print(inputs)\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        #print(title, text)\n",
    "        #print(ids)\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "# Creating the dataset and dataloader for the neural networkkenizer, MAX_LEN)\n",
    "hh_testing_set = Triage(dataset.reset_index(drop=True), tokenizer, HH_MAX_LEN, \"headline\")\n",
    "hh_test_params = {'batch_size': HH_VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "hh_testing_loader = DataLoader(hh_testing_set, **hh_test_params)\n",
    "\n",
    "ha_testing_set = Triage(dataset.reset_index(drop=True), tokenizer, HA_MAX_LEN, \"fulltext\")\n",
    "ha_test_params = {'batch_size': HA_VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "ha_testing_loader = DataLoader(ha_testing_set, **ha_test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output_2 = self.l2(output_1[0])\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    y_target = []\n",
    "    y_predicted = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            total += outputs.size(0)\n",
    "            n_correct += big_idx.sum().item()\n",
    "            \n",
    "    return ((total-n_correct)*100.0)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH_MODEL_PATH = \"h-h-classifier.h5\"\n",
    "model.load_state_dict(torch.load(HH_MODEL_PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_accuracy = valid(model, hh_testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH_MODEL_PATH = \"h-a-classifier.h5\"\n",
    "model.load_state_dict(torch.load(HH_MODEL_PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_accuracy = valid(model, ha_testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines-Headlines match accuracy 59.94505494505494\n",
      "Headlines-Article match accuracy 87.2370486656201\n"
     ]
    }
   ],
   "source": [
    "print(f\"Headlines-Headlines match accuracy {hh_accuracy}\")\n",
    "print(f\"Headlines-Article match accuracy {ha_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
